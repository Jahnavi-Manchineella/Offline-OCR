ğŸ”¬ Advanced OCR System
EasyOCR + TrOCR (Fully Offline Â· Multi-Scale Â· Streamlit UI)

An advanced offline Optical Character Recognition (OCR) system that combines EasyOCR (detection) and Microsoft TrOCR (recognition refinement) using a multi-scale + consensus-based pipeline.

This system supports:

âœ… Image OCR (JPG / PNG)

âœ… Video OCR (MP4 frame-by-frame)

âœ… Multi-scale text detection

âœ… IoU box fusion

âœ… EasyOCR + TrOCR consensus

âœ… Line reconstruction

âœ… Fully offline execution

âœ… Streamlit UI

ğŸ“¦ 1ï¸âƒ£ Submission Files (Mandatory)

Your submission includes:

âœ… Complete project ZIP folder

âœ… Detailed documentation (PDF/DOC)

âœ… Sample outputs inside /outputs/

âœ… README.md (this file)

âœ… requirements.txt

âœ… Working Streamlit app (app.py)

â­ GitHub repository (recommended)

ğŸ—‚ 2ï¸âƒ£ Required Project Structure
project/
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ sample_images/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ trocr_model/
â”œâ”€â”€ test_videos/
â”œâ”€â”€ outputs/
â”œâ”€â”€ main.py
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


Note: In your implementation, trocr_model/ contains locally saved HuggingFace model weights to ensure offline execution.

âš™ï¸ Installation Instructions
1ï¸âƒ£ Create Virtual Environment (Recommended)
python -m venv venv
source venv/bin/activate        # Mac/Linux
venv\Scripts\activate           # Windows

2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

3ï¸âƒ£ Download Models (First Time Only)

Run:

python main.py


This will:

Initialize EasyOCR

Download microsoft/trocr-base-printed

Save model locally inside /trocr_model/

Prepare system for offline inference

After this step â†’ Internet is NOT required.

ğŸš€ Running the Application
streamlit run app.py


Then open browser at:

http://localhost:8501


Upload:

JPG / PNG image

MP4 video

Click Run OCR

ğŸ§  Model Selection Justification
Why EasyOCR?

Strong detection capability

Works offline

Lightweight compared to heavy detection models

Supports multi-scale inference

No cloud API required

Why TrOCR?

Transformer-based OCR model

State-of-the-art recognition accuracy

Robust to noisy / distorted text

Works fully offline after download

Improves recognition quality over EasyOCR raw output

Why Not YOLO?

Assignment restriction:

âŒ Do NOT use YOLO

Additionally:

YOLO requires object detection training

Not necessary for text-only detection

Adds training complexity

ğŸ“Š Dataset Justification

This system is inference-based and does not use COCO or ImageNet.

Why?

âŒ COCO/ImageNet are general object detection datasets

âŒ Not optimized for text recognition

âŒ Assignment restriction

Instead:

System uses pre-trained OCR models

Tested on:

Custom sample images

Real-world text samples

Printed documents

Industrial stencil samples

ğŸ”„ Inference Pipeline (Step-by-Step)

The complete OCR pipeline:

1ï¸âƒ£ Image Preprocessing

Convert to grayscale

Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)

Apply sharpening filter

Create multiple enhanced versions

2ï¸âƒ£ Multi-Scale Detection

Scales used:

[0.75, 1.0, 1.5, 2.0]


For each scale:

Resize image

Run EasyOCR

Rescale bounding boxes back

Filter by confidence threshold

3ï¸âƒ£ IoU Box Fusion

Remove overlapping bounding boxes

Keep highest confidence

Reduce duplicate detections

4ï¸âƒ£ TrOCR Recognition

For each cropped text region:

Convert to RGB

Pass through TrOCR processor

Generate text using transformer decoder

Decode tokens to final text

5ï¸âƒ£ Consensus Merge

Final text = best match between:

EasyOCR output

TrOCR output

Rules:

If one contains the other â†’ keep longer

Else â†’ keep higher quality prediction

6ï¸âƒ£ Line Reconstruction

Group boxes by vertical alignment

Sort left-to-right

Remove duplicates

Build clean readable lines

ğŸ“„ Inference Script (Standalone CLI Version)

You can also run OCR without Streamlit:

# inference.py

import cv2
from main import extract_text_from_image
import numpy as np
from PIL import Image

image_path = "datasets/sample_images/Picture3.jpg"

image = Image.open(image_path).convert("RGB")
image_np = np.array(image)
bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)

output_img, lines, elapsed = extract_text_from_image(bgr)

print("Time:", elapsed)
print("\nExtracted Text:\n")

for line in lines:
    print(line["text"], "| Confidence:", line["confidence"])

cv2.imwrite("outputs/result.jpg", output_img)


Run:

python inference.py

ğŸ“ˆ Metrics Logged

For each run:

Total inference time

Number of lines detected

Average confidence score

Bounding box visualization

Structured JSON output

Example JSON:

[
  {
    "text": "ADVANCED OCR SYSTEM",
    "confidence": 0.91
  },
  {
    "text": "FULLY OFFLINE",
    "confidence": 0.88
  }
]

ğŸ”’ Offline Constraint (Strictly Followed)

âŒ No Google Vision

âŒ No AWS Textract

âŒ No Cloud API

âŒ No Internet during inference

âœ… All models stored locally

âœ… local_files_only=True enforced

System works completely offline after first model download.

âš ï¸ Challenges Faced
1ï¸âƒ£ Duplicate Detections

Multi-scale detection caused repeated boxes.

âœ” Solution:
Implemented IoU-based fusion.

2ï¸âƒ£ Noisy / Low Contrast Text

Low-quality images reduced accuracy.

âœ” Solution:

CLAHE contrast enhancement

Sharpening

Multi-enhancement pipeline

3ï¸âƒ£ Recognition Errors

EasyOCR sometimes produced short/incorrect words.

âœ” Solution:
Consensus merge with TrOCR refinement.

4ï¸âƒ£ Video Processing Performance

Frame-by-frame OCR is computationally heavy.

âœ” Solution:

Efficient caching

Model loaded once

GPU support enabled

ğŸ”§ Possible Improvements

Add language auto-detection

Add beam search tuning in TrOCR

Add batch frame processing

Add PDF batch processing

Add layout-aware text grouping

Implement confidence-weighted consensus

ğŸ“Š Performance Summary
Component	Description
Detection	EasyOCR Multi-Scale
Recognition	TrOCR Transformer
Fusion	IoU-based
Runtime	~1â€“3 sec per image (CPU)
GPU Support	Yes
Offline	Fully
ğŸ¯ AI Technical Assignment Compliance
Requirement	Status
No YOLO	âœ…
No COCO/ImageNet	âœ…
No Cloud APIs	âœ…
Offline execution	âœ…
Proper folder structure	âœ…
Streamlit runs without error	âœ…
Structured output	âœ…
Documentation included	âœ…
ğŸ§ª Sample Outputs

Stored inside:

/outputs/


Includes:

Annotated images

Extracted text files

Screenshots

ğŸ‘©â€ğŸ’» Author

Advanced OCR System
AI Technical Assignment Submission

âœ… Final Verification Checklist

Before submission:

 ZIP folder created

 outputs/ contains sample results

 requirements.txt updated

 README.md included

 Streamlit app runs

 Models downloaded locally

 Documentation PDF added